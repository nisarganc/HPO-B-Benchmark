{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for adding a new search space to HPO-B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will explain how to pre-process a group of flows (e.g. search space) and datasets from OpenML so that it can be added to HPO-B. Although we will focus on a single search space as example, this notebook also resembles the process for creating the original benchmark. However, bear in mind that the original benchmark creation was an iterative process based on the main steps presented here. \n",
    "\n",
    "First, we will import the main libraries that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will select a specific flow ID, however, this ID is just a placeholder that corresponds to potential new flows added to OpenML. This example is valid for a list of flows, although we select only one flow. The function **list_runs** will return the ID of specific runs, but not the actual hyperparameter configurations and responses. This information will be queried later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_id = 423\n",
    "runs = openml.runs.list_runs(flow = [flow_id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a matrix to structure the runs, such that we can differentiate the runs belonging to a specific flow and dataset. Afterwards, we define a list of selected datasets and flows, which involves only 100 datasets for the sake of simplicity. The original benchmark creation specified some restrictions on the number of runs per flow and dataset. For more information regarding this, please refer to **data_creation.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = defaultdict(lambda: defaultdict(list))#or set?\n",
    "\n",
    "for run in runs.values():\n",
    "    matrix[run[\"flow_id\"]][run[\"task_id\"]].append(run['run_id']) \n",
    "    \n",
    "selected_datasets_ids = list(matrix[flow_id].keys())[:100] #limiting to 100 datasets for demonstration purposes\n",
    "selected_flows_ids = [flow_id]*len(selected_datasets_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we query the actual runs. Notice that we do it using batches of 1000 runs to avoid overload on the servers. We also keep an index accounting for the current position in the list of selected datasets. Like this, it is possible to resume the download of runs in case the process stops by just speciying assigning the highest index to **starting_idx**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: 1  and flow:  423  position: 0\n",
      "Processing dataset: 13  and flow:  423  position: 10\n",
      "Processing dataset: 27  and flow:  423  position: 20\n",
      "Processing dataset: 40  and flow:  423  position: 30\n",
      "Processing dataset: 53  and flow:  423  position: 40\n",
      "Processing dataset: 235  and flow:  423  position: 50\n",
      "Processing dataset: 248  and flow:  423  position: 60\n",
      "Processing dataset: 264  and flow:  423  position: 70\n",
      "Processing dataset: 277  and flow:  423  position: 80\n",
      "Processing dataset: 288  and flow:  423  position: 90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_run_settings (settings):\n",
    "    parameter_dict ={}\n",
    "    for setting in settings:\n",
    "        value = setting[\"oml:value\"]\n",
    "        parameter_dict[setting[\"oml:name\"]] = value\n",
    "\n",
    "    return parameter_dict\n",
    "\n",
    "starting_idx = 0\n",
    "meta_dataset = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for idx, (dataset, flow) in enumerate(zip(selected_datasets_ids[starting_idx:], selected_flows_ids[starting_idx:])):\n",
    "    \n",
    "    if idx%10==0:\n",
    "        print(\"Processing dataset:\", dataset, \" and flow: \", flow, \" position:\",idx)\n",
    "    \n",
    "    \n",
    "    run_list = list(matrix[flow][dataset])\n",
    "    \n",
    "    for run_list_idx in range(0, max(2000,len(run_list)), 1000):\n",
    "\n",
    "        \n",
    "        current_runs = openml.runs.get_runs(list(run_list)[run_list_idx:run_list_idx+1000])\n",
    "\n",
    "        for i, current_run in enumerate(current_runs):\n",
    "\n",
    "            temp_dict = {}\n",
    "            temp_dict[\"run_id\"] = run_list[i]\n",
    "            temp_dict[\"task_id\"] = current_run.task_id\n",
    "            temp_dict[\"flow_name\"] = current_run.flow_name\n",
    "            temp_dict[\"accuracy\"] = current_run.evaluations[\"predictive_accuracy\"]\n",
    "            temp_dict[\"parameter_settings\"] =  process_run_settings (current_run.parameter_settings)\n",
    "            meta_dataset[flow][dataset].append(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casting hyperparameters type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As originally all the hyperparameter values are string, we need to cast them to the original type. For this, we consider a hyperparameter to be either integer, float or string. Moreover, we create a **check_value** function  that checks weather the value of hyperparameter is valid. Although we are checking the length, this part is fully customizable as it can be checked whether a hyperparameter is within a range or follows a specific format. In case the hyperparameter does not comply the checking conditions, it is not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset_checkpoint1 = defaultdict(lambda: defaultdict(list))\n",
    "max_len = 2000\n",
    "\n",
    "check_value = lambda x: len(value)<max_len\n",
    "\n",
    "for flow_id in meta_dataset.keys():\n",
    "    for dataset_id in meta_dataset[flow_id].keys():\n",
    "        for run_id, run in enumerate(meta_dataset[flow_id][dataset_id]):\n",
    "            append_run = 1\n",
    "            for parameter in run[\"parameter_settings\"].keys():\n",
    "                try:\n",
    "                    try:\n",
    "                        run[\"parameter_settings\"][parameter]= int(run[\"parameter_settings\"][parameter])\n",
    "                    except:\n",
    "                        run[\"parameter_settings\"][parameter]= float(run[\"parameter_settings\"][parameter])\n",
    "                except:\n",
    "                    value = run[\"parameter_settings\"][parameter]\n",
    "\n",
    "                    if value is not None:\n",
    "                        if not check_value(value):\n",
    "                            append_run = 0\n",
    "            if append_run == 1:\n",
    "                    meta_dataset_checkpoint1[flow_id][dataset].append(run)\n",
    "                    \n",
    "with open('meta_dataset_ckechpoint1.json', 'w') as outfile:\n",
    "    json.dump(meta_dataset_checkpoint1, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, some datasets may not have enough evaluations, thus are unuseful or may contain wrong evaluations. Therefore, we exclude all their runs from the final meta-dataset. In here, we filter out the datasets with one unique evaluations, but the selection rule can involve more complex conditions, referring for instance, to the dimensionality of the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Filtering if it has invalid evaluation\n",
    "exclude_list = []\n",
    "\n",
    "for flow_id in meta_dataset_checkpoint1.keys():\n",
    "    for dataset_id in meta_dataset_checkpoint1[flow_id].keys():\n",
    "        run_parameters=[run[\"parameter_settings\"] for run in  meta_dataset_checkpoint1[flow_id][dataset_id]]\n",
    "        counter= {}\n",
    "        for run in run_parameters:\n",
    "            for param, value in run.items():\n",
    "                if param in counter.keys():\n",
    "                    counter[param].append(value)\n",
    "                else:\n",
    "                    counter[param] = []\n",
    "        only_ones = True\n",
    "        for key, values in counter.items():\n",
    "            try:\n",
    "                only_ones= only_ones and (np.unique(values).shape[0]==1)\n",
    "            except:\n",
    "                pass\n",
    "        if only_ones: \n",
    "            exclude_list.append((dataset_id, flow_id))\n",
    "\n",
    "#filtering meta-dataset (getting rid of data in the blacklist)\n",
    "meta_dataset_checkpoint2 = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for flow_id in meta_dataset_checkpoint1.keys():\n",
    "    for dataset_id in meta_dataset_checkpoint1[flow_id].keys():\n",
    "        if (dataset_id, flow_id) not in exclude_list:\n",
    "            for run in meta_dataset_checkpoint1[flow_id][dataset_id]:\n",
    "                meta_dataset_checkpoint2[flow_id][dataset_id].append(run)\n",
    "\n",
    "with open('meta_dataset_ckechpoint2.json', 'w') as outfile:\n",
    "    json.dump(meta_dataset_checkpoint2, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation and hyperparameter transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to impute, transform and filter hyperparameters. Before this, we merge all the datasets within the same search space into a \"single view\", a dataframe that contains the hyperparameters as columns and the runs as rows. This integrated dataframe allows comparing among datasets, so that the normalization considers all the whole range of values. \n",
    "\n",
    "During the imputation, we create a new column that specifies whether a hyperparameter had no value (or invalid value). Similarly, if a hyperparameter only has one value across the datasets, we delete it. Finally, we also specify which hyperparameters receive a log-transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(set_of_runs):\n",
    "    df = pd.DataFrame([run[\"parameter_settings\"] for run in set_of_runs])\n",
    "    df[\"accuracy\"] = [run[\"accuracy\"] for run in set_of_runs]\n",
    "    df[\"dataset\"] = [run[\"task_id\"] for run in set_of_runs] \n",
    "    return df\n",
    "\n",
    "def get_hps_to_keep(df):\n",
    "    \n",
    "    nunique = df.nunique()\n",
    "    hps_to_keep = list(df.columns[nunique>1])\n",
    "    return hps_to_keep\n",
    "\n",
    "def get_hps_to_apply_log(df):\n",
    "    \n",
    "    return []\n",
    "\n",
    "def normalize(x):\n",
    "    \n",
    "    return (x-min(x))/(max(x)-min(x))\n",
    "\n",
    "\n",
    "def impute_dataframe(df):\n",
    "    df = df.replace(\"None\", np.nan)\n",
    "    df_ = pd.DataFrame()\n",
    "    \n",
    "    columns = list(df.columns)\n",
    "    columns.remove(\"accuracy\")\n",
    "    columns.remove(\"dataset\")\n",
    "    for column in columns:\n",
    "\n",
    "        if(df[column].dtype == \"float64\" ):\n",
    "            df_na = df[[column]].isna().astype(float)\n",
    "            df_na.columns += \".na\"\n",
    "            df_ = pd.concat((df_, df[[column]].fillna(0.0), df_na), axis=1)\n",
    "        elif df[column].dtype == \"int\" :\n",
    "            df_na = df[[column]].isna().astype(int)\n",
    "            df_na.columns += \".na\"\n",
    "            df_ = pd.concat((df_, df[[column]].fillna(0.0), df_na), axis=1)            \n",
    "        else:\n",
    "            df[[column]] = df[[column]].fillna(\"INVALID\")\n",
    "            df_ = pd.concat((df_, df[[column]]), axis=1)\n",
    "\n",
    "    return df_\n",
    "\n",
    "hps_to_keep = dict()\n",
    "hps_to_apply_log = dict()\n",
    "single_views = dict()\n",
    "\n",
    "for flow_id in meta_dataset_checkpoint2.keys():\n",
    "    single_view_hp = pd.DataFrame()\n",
    "    for dataset_id in meta_dataset_checkpoint2[flow_id].keys():\n",
    "        temp_df = get_dataframe(meta_dataset_checkpoint2[flow_id][dataset_id])\n",
    "        single_view_hp = pd.concat((single_view_hp, temp_df))\n",
    "        \n",
    "    single_views[flow_id] = impute_dataframe(single_view_hp)\n",
    "    hps_to_keep[flow_id] = get_hps_to_keep(single_views[flow_id] )\n",
    "    hps_to_apply_log[flow_id] = get_hps_to_apply_log(single_views[flow_id] )\n",
    "\n",
    "    for hp in single_views[flow_id].columns:\n",
    "        if hp in hps_to_keep[flow_id]:\n",
    "            if hp in hps_to_apply_log[flow_id]:\n",
    "                single_views[flow_id][hp] = np.log(single_views[flow_id][hp])\n",
    "            single_views[flow_id][hp] = normalize(single_views[flow_id][hp])\n",
    "        else:\n",
    "            del single_views[flow_id][hp]\n",
    "    \n",
    "    single_views[flow_id][\"accuracy\"] = single_view_hp[\"accuracy\"]\n",
    "    single_views[flow_id][\"dataset\"] = single_view_hp[\"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{423:             I  accuracy  dataset\n",
       " 0    0.000000  0.993318        1\n",
       " 1    0.066667  0.993318        1\n",
       " 2    0.200000  0.992205        1\n",
       " 3    0.000000  0.893096        2\n",
       " 4    0.066667  0.898664        2\n",
       " ..        ...       ...      ...\n",
       " 475  0.466667  0.678049     1773\n",
       " 476  0.000000  0.824324     1774\n",
       " 477  0.066667  0.821622     1774\n",
       " 478  0.200000  0.818919     1774\n",
       " 479  0.466667  0.820270     1774\n",
       " \n",
       " [480 rows x 3 columns]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the meta-dataset for new the search space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have imputed and transformed the hyperparameters, we create the final json object. In Python, this corresponds to a nested dictionary, where we assign the flow ID as the first level key, and the second level key as the dataset ID. A quick example of how this should look like:\n",
    "\n",
    "```python\n",
    "meta_dataset = { \"flow_id_1\" : { \"dataset_id_1\": {\"X\": [[1,1], [0,2]],\n",
    "                                                  \"y\": [[0.9], [0.1]]},\n",
    "                               { \"dataset_id_2\": ... },\n",
    "                 \"flow_id_2\" : ...\n",
    "                                \n",
    "                }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dataset_new_space = {}\n",
    "output_path = \"../data/\"\n",
    "\n",
    "for flow_id in single_views.keys():\n",
    "    \n",
    "    df = single_views[flow_id]\n",
    "    flow_id = str(flow_id)\n",
    "    cols = list(df.columns)    \n",
    "    [cols.remove(x) for x in [\"dataset\", \"accuracy\"]]\n",
    "    datasets_list = df[\"dataset\"].unique()\n",
    "    meta_dataset_new_space [flow_id] = {}\n",
    "    for dataset in datasets_list:\n",
    "        df_temp = df[df[\"dataset\"]==dataset]\n",
    "        dataset = str(dataset)\n",
    "        if(df_temp.shape[0]>0):\n",
    "            meta_dataset_new_space[flow_id][dataset] = {\"X\": df_temp[cols].to_numpy().tolist(),\n",
    "                                                 \"y\": df_temp[\"accuracy\"].to_numpy().tolist()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can inspect and save the created dictionary. We can see that the format matches to our previous descriptioin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': [[0.0], [0.06666666666666667], [0.2]],\n",
       " 'y': [0.993318, 0.993318, 0.992205]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id=\"1\"\n",
    "meta_dataset_new_space[flow_id][dataset_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('meta_dataset_new_space.json', 'w') as outfile:\n",
    "    json.dump(meta_dataset_new_space, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating HPO-B with the new search space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have created a meta-dataset on new search-spaces by following the above described format, we can update HPO-B easily. In case we use the provided API, we just need to update the meta-test-data attribute, which is a dictionary. Notice that this procedure, however, may differ depending on the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HPO-B handler\n",
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from hpob_handler import HPOBHandler\n",
    "\n",
    "hpob_hdlr = HPOBHandler(root_dir=\"../hpob-data/\", mode=\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpob_hdlr.meta_test_data.update(meta_dataset_new_space)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}